# Network Generation

This is the code used to generate N networks for the N-version programming. This code is also used to generate a network which has no teacher and a network using a teacher. The N networks are have architectures loaded from a text file which the user creates. The networks are then trained using a predefined set of epochs and hyper-parameters.

## N Networks

### Prerequists

This code looks for a network specified as an argument in directory called NetworkArchitecture. The networks need to be described using any of the following layers:

* Convolutional layer: conv, filters, activation function - `conv, 8, relu`
* Dense layer: dense, neurons, activation function - `dense, 256, relu`
* Maxpooling2D layer: maxpooling - `maxpooling`
* Flattern layer: flattern - `flattern`

### Running the code

You can run the code on an individual network using:

```
$ python3 network_creator.py "{network file}"
```

You can also run the provided scripts to train large sets of networks. To use them run:

```
$ ./run.sh
```

## Creating the Network with No Teacher

This will create a network which is trained on the Mnist dataset. This will be used as a baseline network

### Running the code

To train the network you can run

```
$ python3  single_network_noteacher.py
```

The output will be saved in a folder `.\TeacherNetworks`

## Creating the Teacher Student Network

This will use the labels generated by the teacher to train a network. The network will attempt to minimize the loss between the teacher labels and its output. You will need to have generated the teacher labels before running this. You can generate the teacher labels in the Net-Use folder.

### Running the code

## Authors

* **Carl Hildebrandt** - *Initial work* - [hildebrandt-carl](https://github.com/hildebrandt-carl)
